{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GitHub_DAPT_Phase_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "H61BeQWCDyYH"
      },
      "source": [
        "#import the necessary libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import os\n",
        "from keras import models \n",
        "from keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gv5N44ethHhn",
        "outputId": "1dca1fcb-78cf-4f3b-8fa8-92b843693185"
      },
      "source": [
        "#Mount Google drive\n",
        "#Run this cell only if your data (npy files of LGG and HGG reside on Google \n",
        "#drive)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Set base_path to the location where the data and results of your project\n",
        "#reside\n",
        "base_path = '/content/gdrive/MyDrive/HPT/'"
      ],
      "metadata": {
        "id": "-O2JO9N9ZHrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image shape set to constant for further use\n",
        "# 240, 240 is the size of a slice in BraTS dataset. Same image/slice\n",
        "# is copied to the 3 channels. We need to have 3 channels because we\n",
        "# are using pre-trained ResNet50 (or its variant)\n",
        "IMG_SHAPE = (240, 240, 3)"
      ],
      "metadata": {
        "id": "5uda6Z3MNCe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preparing TrainX and TrainY\n",
        "Loading HGG and LGG data stored in .npy files. Creating their labels: 0 for LGG and 1 for HGG. Finally, the data and the corresponding labels will be shuffled randomly."
      ],
      "metadata": {
        "id": "RxPZpGQ4tIoh"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un3NfVF6fjF5"
      },
      "source": [
        "HGG_cases = 19496\n",
        "LGG_cases = 4926\n",
        "Total_cases = HGG_cases + LGG_cases"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7iTNC9nfjF5"
      },
      "source": [
        "#creating a NumPy array for holding all the training data (TrainX)\n",
        "TrainX = np.zeros((Total_cases, 240 , 240, 3), dtype=np.float16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "np_7-P3HfjF5",
        "outputId": "083694c2-37d0-42af-b472-9d91cdbae573"
      },
      "source": [
        "print (TrainX.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "float16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7Ifip27fqFP"
      },
      "source": [
        "#function to load HGG cases stored in BraTS2020_Tumorous_HGG_T1_f16.npy\n",
        "def read_HGG():\n",
        "  HGG_data_one_channel = np.load(base_path + 'Datasets/BraTS2020/BraTS2020_Tumorous_HGG_T1_f16.npy')\n",
        "  print (HGG_data_one_channel.shape)\n",
        "  print (HGG_data_one_channel.dtype)\n",
        "\n",
        "  for i in range (HGG_data_one_channel.shape[0]):\n",
        "    TrainX[i, :, :, 0] = HGG_data_one_channel[i, :, :]\n",
        "    TrainX[i, :, :, 1] = HGG_data_one_channel[i, :, :]\n",
        "    TrainX[i, :, :, 2] = HGG_data_one_channel[i, :, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mCDJGOif6oW"
      },
      "source": [
        "#function to load LGG cases stored in BraTS2020_Tumorous_LGG_T1_f16.npy\n",
        "def read_LGG():\n",
        "  LGG_data_one_channel = np.load(base_path + 'Datasets/BraTS2020/BraTS2020_Tumorous_LGG_T1_f16.npy')\n",
        "  print (LGG_data_one_channel.shape)\n",
        "  print (LGG_data_one_channel.dtype)\n",
        "\n",
        "  for i in range (LGG_data_one_channel.shape[0]):\n",
        "    TrainX[i + HGG_cases, :, :, 0] = LGG_data_one_channel[i, :, :]\n",
        "    TrainX[i + HGG_cases, :, :, 1] = LGG_data_one_channel[i, :, :]\n",
        "    TrainX[i + HGG_cases, :, :, 2] = LGG_data_one_channel[i, :, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zycSDA2guxG",
        "outputId": "0b47925c-d2da-42a1-c920-ced0f473bb58"
      },
      "source": [
        "#call the function read_HGG() to load HGG data to TrainX\n",
        "read_HGG()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19496, 240, 240)\n",
            "float16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nBZ1iIbgxu-",
        "outputId": "d0457faf-8df7-4e99-e967-58a0c6f77683"
      },
      "source": [
        "#call the function read_LGG() to load LGG data to TrainX\n",
        "read_LGG()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4926, 240, 240)\n",
            "float16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEJrY5zNEhy9"
      },
      "source": [
        "#function to define labels. i.e. 1 for HGG and 0 LGG cases\n",
        "def define_labels():\n",
        "  HGG_labels = np.ones(shape=(HGG_cases,1), dtype='uint8')\n",
        "  LGG_labels = np.zeros(shape=(LGG_cases,1), dtype='uint8')\n",
        "\n",
        "  return (np.concatenate((HGG_labels, LGG_labels), axis=0))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9eHk6N1EnC2"
      },
      "source": [
        "#Call the function to create labels and store in TrainY \n",
        "TrainY = define_labels()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sy5kOufffjF_",
        "outputId": "636fbdab-a7ff-4fda-b340-0d8202db5604"
      },
      "source": [
        "#Printing the shape of TrainX and TrainY\n",
        "print (TrainX.shape)\n",
        "print (TrainY.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(24422, 240, 240, 3)\n",
            "(24422, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1_EV1wnEpb1"
      },
      "source": [
        "#Shuffle the data in TrainX and TrainY\n",
        "p = np.random.permutation(TrainX.shape[0])\n",
        "TrainX = TrainX[p]\n",
        "TrainY = TrainY[p]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Phase 1 of DAPT (Start for the First Time)\n",
        "Run the following cells only when starting DAPT (phase 1) for a particular \n",
        "strategy for the first time. **DO NOT** run the following cells if you are\n",
        "resuming phase 1 of DAPT after some epochs.\n",
        "\n",
        "#All the layers of the architecture will be frozen except the last layer (sigmoid) for 1000 epochs"
      ],
      "metadata": {
        "id": "IL4fmcLEsKUY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QbKr0siD8e0",
        "outputId": "439841b8-28b6-4c87-cd20-d4f6a3f4e333"
      },
      "source": [
        "# Loading the convolution base of ResNet50 with ImageNet pre-trained \n",
        "# weights\n",
        "base_model = tf.keras.applications.ResNet50(input_shape=IMG_SHAPE, \n",
        "                                               include_top=False, \n",
        "                                               weights=\"imagenet\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 0s 0us/step\n",
            "94781440/94765736 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1_HrTiVEJt8",
        "outputId": "34e2efc1-af96-4648-fd1d-e55c83eeb34b"
      },
      "source": [
        "# Printing the summary of the base_model and its layers\n",
        "base_model.summary()\n",
        "print (len(base_model.layers))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 240, 240, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 246, 246, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 120, 120, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 120, 120, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 120, 120, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 122, 122, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 60, 60, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 60, 60, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 60, 60, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 60, 60, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 60, 60, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 60, 60, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 60, 60, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 60, 60, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 60, 60, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 60, 60, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 60, 60, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 60, 60, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 60, 60, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 60, 60, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 60, 60, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 60, 60, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 60, 60, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 60, 60, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 60, 60, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 60, 60, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 60, 60, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 60, 60, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 60, 60, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 60, 60, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 60, 60, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 60, 60, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 60, 60, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 60, 60, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 60, 60, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 60, 60, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 60, 60, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 60, 60, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 60, 60, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 30, 30, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 30, 30, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 30, 30, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 30, 30, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 30, 30, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 30, 30, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 30, 30, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 30, 30, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 30, 30, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 30, 30, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 30, 30, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 30, 30, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 30, 30, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 30, 30, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 30, 30, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 30, 30, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 30, 30, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 30, 30, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 30, 30, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 30, 30, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 30, 30, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 30, 30, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 30, 30, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 30, 30, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 30, 30, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 30, 30, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 30, 30, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 30, 30, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 30, 30, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 30, 30, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 30, 30, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 30, 30, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 30, 30, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 30, 30, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 30, 30, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 30, 30, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 30, 30, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 30, 30, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 30, 30, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 30, 30, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 30, 30, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 30, 30, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 15, 15, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 15, 15, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 15, 15, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 15, 15, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 15, 15, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 15, 15, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 15, 15, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 15, 15, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 15, 15, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 15, 15, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 15, 15, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 15, 15, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 15, 15, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 15, 15, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 15, 15, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 15, 15, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 15, 15, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 15, 15, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 15, 15, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 15, 15, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 15, 15, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 15, 15, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 15, 15, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 15, 15, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 15, 15, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 15, 15, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 15, 15, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 15, 15, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 15, 15, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 15, 15, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 15, 15, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 15, 15, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 15, 15, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 15, 15, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 15, 15, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 15, 15, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 15, 15, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 15, 15, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 15, 15, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 15, 15, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 15, 15, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 15, 15, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 15, 15, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 15, 15, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 15, 15, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 15, 15, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 15, 15, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 15, 15, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 15, 15, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 15, 15, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 15, 15, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 8, 8, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 8, 8, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 8, 8, 2048)   0           conv5_block3_add[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n",
            "175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transfuse_weights(simple_architecture):\n",
        "  for i, layer in enumerate(base_model.layers):\n",
        "  Flag = 0\n",
        "  for j, trans_layer in enumerate(simple_architecture.layers): \n",
        "    if layer.name==trans_layer.name:\n",
        "      #counter = counter + 1\n",
        "      #Flag = 1\n",
        "      simple_architecture.layers[j].set_weights(base_model.layers[i].get_weights())\n",
        "    if Flag == 0:\n",
        "      print (i, layer.name)\n",
        "\n",
        "  return simple_architecture"
      ],
      "metadata": {
        "id": "9p_Y6vemSnqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This function creates an architecture based on the first one block\n",
        "#of the ResNet50 architecture and trans\n",
        "def create_first_one_block_architecture():\n",
        "\n",
        "  img_input = layers.Input(shape=IMG_SHAPE) #input layer\n",
        "  x = img_input\n",
        "  for i, layer in enumerate(base_model.layers):\n",
        "    if i >= 1 and i<= 12:\n",
        "      x = layer(x)\n",
        "      if i == 6:\n",
        "        temp1 = x\n",
        "    elif i == 13:\n",
        "      shortcut1 = layer(temp1)\n",
        "    elif i == 14:\n",
        "      x = layer(x)\n",
        "    elif i == 15:\n",
        "      shortcut1 = layer(shortcut1)\n",
        "    elif i == 16:\n",
        "      x = layer(x)\n",
        "    elif i == 17:\n",
        "      x = layers.add([x, shortcut1])\n",
        "    elif i >= 18 and i <= 26:\n",
        "      x = layer(x)\n",
        "      if i == 18:\n",
        "        temp2 = x\n",
        "    elif i == 27:\n",
        "      x = layers.add([x, temp2])\n",
        "    elif i >= 28 and i <= 36:\n",
        "      x = layer(x)\n",
        "      if i == 28:\n",
        "        temp3 = x\n",
        "    elif i == 37:\n",
        "      x = layers.add([x, temp3]) \n",
        "    elif i==38:\n",
        "      x = layer(x)\n",
        "\n",
        "  x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "  x = layers.Dense(1, activation='sigmoid', name='fc')(x)\n",
        "  DA_TF_F1B_model = models.Model(img_input, x, name='DA_TF_F1B')\n",
        "\n",
        "  DA_TF_F1B_model = transfuse_weights(DA_TF_F1B_model)\n",
        "  return DA_TF_F1B_model"
      ],
      "metadata": {
        "id": "YuLFoDKYOFAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_first_two_blocks_architecture():\n",
        "  img_input = layers.Input(shape=IMG_SHAPE) #input layer\n",
        "  x = img_input\n",
        "  for i, layer in enumerate(base_model.layers):\n",
        "    if i >= 1 and i<= 12:\n",
        "      x = layer(x)\n",
        "      if i == 6:\n",
        "        temp1 = x\n",
        "    elif i == 13:\n",
        "      shortcut1 = layer(temp1)\n",
        "    elif i == 14:\n",
        "      x = layer(x)\n",
        "    elif i == 15:\n",
        "      shortcut1 = layer(shortcut1)\n",
        "    elif i == 16:\n",
        "      x = layer(x)\n",
        "    elif i == 17:\n",
        "      x = layers.add([x, shortcut1])\n",
        "    elif i >= 18 and i <= 26:\n",
        "      x = layer(x)\n",
        "      if i == 18:\n",
        "        temp2 = x\n",
        "    elif i == 27:\n",
        "      x = layers.add([x, temp2])\n",
        "    elif i >= 28 and i <= 36:\n",
        "      x = layer(x)\n",
        "      if i == 28:\n",
        "        temp3 = x\n",
        "    elif i == 37:\n",
        "      x = layers.add([x, temp3]) \n",
        "    elif i==38:\n",
        "      x = layer(x)\n",
        "    elif i >= 38 and i <= 44:\n",
        "      x = layer(x)\n",
        "      if i == 38:\n",
        "        temp4 = x\n",
        "    elif i == 45:\n",
        "      shortcut2 = layer(temp4)\n",
        "    elif i == 46: \n",
        "      x = layer(x)\n",
        "    elif i == 47:\n",
        "      shortcut2 = layer(shortcut2)\n",
        "    elif i == 48:\n",
        "      x = layer(x)\n",
        "    elif i == 49:\n",
        "      x = layers.add([x, shortcut2])\n",
        "    elif i >= 50 and i <= 58:\n",
        "      x = layer(x)\n",
        "      if i == 50:\n",
        "        temp5 = x\n",
        "    elif i == 59:\n",
        "      x = layers.add([x, temp5])\n",
        "    elif i >= 60 and i <= 68:\n",
        "      x = layer(x)\n",
        "      if i == 60:\n",
        "        temp6 = x\n",
        "    elif i == 69:\n",
        "      x = layers.add([x, temp6])\n",
        "    elif i >= 70 and i <= 78:\n",
        "      x = layer(x)\n",
        "      if i == 70:\n",
        "        temp7 = x\n",
        "    elif i == 79:\n",
        "      x = layers.add([x, temp7])\n",
        "    elif i == 80:\n",
        "      x = layer(x)\n",
        "  \n",
        "  x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "  x = layers.Dense(1, activation='sigmoid', name='fc')(x)\n",
        "  DA_TF_F2B_model = models.Model(img_input, x, name='DA_TF_F2B')\n",
        "\n",
        "  DA_TF_F2B_model = transfuse_weights(DA_TF_F2B_model)\n",
        "  return DA_TF_F2B_model"
      ],
      "metadata": {
        "id": "2SRmKjHDOPCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeXyAU8QEMps"
      },
      "source": [
        "#This function returns the model for the given strategy\n",
        "def create_architecture(strategy):\n",
        "\n",
        "  if strategy = \"DA_TF_F1B\":\n",
        "    final_model = create_first_one_block_architecture()\n",
        "  elif strategy = \"DA_TF_F2B\":\n",
        "    final_model = create_first_two_blocks_architecture()\n",
        "  else:\n",
        "    x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "    x = layers.Dense(1, activation='sigmoid', name='fc')(x)\n",
        "    final_model = models.Model(inputs=base_model.input,\n",
        "                              outputs=x)\n",
        "\n",
        "  return final_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####################################################\n",
        "#You need to run phase 1 of DAPT for all the strategies\n",
        "#Please use the variable \"Strategy\" and assign it the \n",
        "#name of the strategy for which you are running the \n",
        "#experiment.\n",
        "#####################################################\n",
        "Strategy = \"DA_TF_F1B\" #choose your strategy \n",
        "phase_1_model = create_architecture(Strategy)"
      ],
      "metadata": {
        "id": "Yss7SPrm_s9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "un_freeze_from = -2 #freeze all the layers except the last 2\n",
        "for layer in phase_1_model.layers[:un_freeze_from]:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "Zx4ACGP2_tBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Verify that all the layers of the convolution base are frozen\n",
        "for j, layer in enumerate(phase_1_model.layers):\n",
        "  print (j, layer.name, layer.trainable)"
      ],
      "metadata": {
        "id": "oLGsCWljX5ST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compile the model\n",
        "phase_1_model.compile(optimizer=optimizers.Adam(learning_rate=0.0001),\n",
        "              loss=losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=[metrics.BinaryAccuracy()])"
      ],
      "metadata": {
        "id": "L6gr6ly_YPgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the paths where checkpoints will be saved after every epoch\n",
        "#We need to set different paths for saving DA_TF_F1B and DA_TF_F2B\n",
        "#As the phase 1 DAPT for all the strategies based on full ResNet50 is the same,\n",
        "#all of the checkpoints of phase 1 for these strategies are saved at one path. \n",
        "if Strategy=\"DA_TF_F1B\" or Strategy=\"DA_TF_F2B\":\n",
        "  checkpoint_path = base_path + 'DAPT/Checkpoints/' + Strategy + '/phase_1'\n",
        "else: \n",
        "  checkpoint_path = base_path + 'DAPT/Checkpoints/Full Architectures/phase_1'\n",
        "\n",
        "#Define callback to save the model after every epoch\n",
        "callbacks = []\n",
        "callbacks.append(ModelCheckpoint(checkpoint_path + '/checkpoint-{epoch}.h5'))"
      ],
      "metadata": {
        "id": "EiVn8LDKYj6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the total epochs, initial epoch number and batch_size for phase 1 DAPT\n",
        "total_epochs = 1000\n",
        "batchSize=16\n",
        "initial_epoch_number = 0"
      ],
      "metadata": {
        "id": "4juMrCdfbJyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Start DAPT phase 1\n",
        "history = phase_1_model.fit(TrainX, TrainY,  batch_size=batchSize, \n",
        "                    epochs=total_epochs,\n",
        "                    initial_epoch=initial_epoch_number,\n",
        "                    verbose=2,\n",
        "                    callbacks=callbacks)"
      ],
      "metadata": {
        "id": "d57tHQegdmsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 1 of DAPT (Resume Training)\n",
        "Run the following cells only when resuming DAPT (phase 1) for a particular \n",
        "strategy from a particular epoch number. **DO NOT** run the following cells if you are\n",
        "starting phase 1 of DAPT from epoch no. 0.\n",
        "\n",
        "#The most recent checkpoint will be loaded and training will be resumed from where it was interrupted."
      ],
      "metadata": {
        "id": "Ntq0GFc5tofY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eEFPGYtEPQ8"
      },
      "source": [
        "#Set the paths where checkpoints will be saved after every epoch\n",
        "#We need to set different paths for saving DA_TF_F1B and DA_TF_F2B\n",
        "#As the phase 1 DAPT for all the strategies based on full ResNet50 is the same,\n",
        "#all of the checkpoints of phase 1 for these strategies are saved at one path. \n",
        "if Strategy=\"DA_TF_F1B\" or Strategy=\"DA_TF_F2B\":\n",
        "  checkpoint_path = base_path + 'DAPT/Checkpoints/' + Strategy + '/phase_1'\n",
        "else: \n",
        "  checkpoint_path = base_path + 'DAPT/Checkpoints/Full Architectures/phase_1'\n",
        "\n",
        "#Define callback to save the model after every epoch\n",
        "callbacks = []\n",
        "callbacks.append(ModelCheckpoint(checkpoint_path + '/checkpoint-{epoch}.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the total epochs and batch_size for phase 1 DAPT\n",
        "total_epochs = 1000\n",
        "batchSize=16"
      ],
      "metadata": {
        "id": "Gi8-E8bTuxDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set the epoch number from where the training will be resumed.\n",
        "initial_epoch_number = 50 \n",
        "\n",
        "#loading the saved checkpoint from where to resume training \n",
        "phase_1_model = models.load_model(checkpoint_path + '/checkpoint-' + str(initial_epoch_number) + '.h5')"
      ],
      "metadata": {
        "id": "2m0IDLVlu41C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Resume DAPT phase 1 training\n",
        "history = phase_1_model.fit(TrainX, TrainY,  batch_size=batchSize, \n",
        "                    epochs=total_epochs,\n",
        "                    initial_epoch=initial_epoch_number,\n",
        "                    verbose=2,\n",
        "                    callbacks=callbacks)"
      ],
      "metadata": {
        "id": "gJ6tsNNpvXeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#END OF PHASE 1 DAPT"
      ],
      "metadata": {
        "id": "X38-dtFCvoXq"
      }
    }
  ]
}